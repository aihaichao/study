{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可以走通的示例程序"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "使用 spark.sql 和 hive_context.sql 都可以\n",
    "注意：partitionBy 的分区字段的内容不能含有中文 (不识别中文)，     md5加密 试试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# from pyspark.sql import HiveContext Row\n",
    "\n",
    "from pyspark import SparkConf, SparkContext, HiveContext\n",
    "\n",
    "from pyspark.sql import SparkSession, HiveContext\n",
    "\n",
    "def spark_hive2():\n",
    "    master=\"local\"  #yarn\n",
    "    conf=SparkConf().setAppName(\"ManageReport\").setMaster(master)\n",
    "    sc=SparkContext(conf=conf)\n",
    "    # sc.setCheckpointDir(u\"\")\n",
    "    hive_context=HiveContext(sc)\n",
    "\n",
    "    path = \"hdfs://172.172.172.166:8020/tmp/test/spark-test.csv\"\n",
    "\n",
    "    financeDF = hive_context.read.csv(path, header=True,)\n",
    "    # financeDF.printSchema()\n",
    "\n",
    "    financeDF.registerTempTable(\"finance\")\n",
    "    financeBasicDF = hive_context.sql(\"\"\"select * from finance limit 10\"\"\")\n",
    "    financeBasicDF.show()\n",
    "\n",
    "    financeBasicDF.write.mode(\"overwrite\").saveAsTable(\"finance_hive\")\n",
    "    financeBasicDF.show()\n",
    "    hive_context.sql(\"\"\" select * from finance_hive\"\"\").show()\n",
    "\n",
    "\n",
    "\n",
    "def spark_hive1():\n",
    "    master=\"local\"  #yarn\n",
    "    conf=SparkConf().setAppName(\"ManageReport\").setMaster(master)\n",
    "    sc=SparkContext(conf=conf)\n",
    "    # sc.setCheckpointDir(u\"\")\n",
    "    hive_context=HiveContext(sc)\n",
    "\n",
    "    path = \"hdfs://172.172.172.166:8020/tmp/test/spark-test.csv\"\n",
    "\n",
    "    financeDF = hive_context.read.csv(path, header=True)\n",
    "    # financeDF.printSchema()\n",
    "\n",
    "    financeDF.createOrReplaceTempView(\"finance\")\n",
    "    financeBasicDF = hive_context.sql(\"\"\"select * from finance \"\"\")\n",
    "    # financeBasicDF.show()\n",
    "    # financeBasicDF.cache()\n",
    "    # financeBasicDF.registerTempTable('finance_tepm')\n",
    "\n",
    "    # spark is an existing SparkSession\n",
    "    # spark.sql(\"CREATE TABLE IF NOT EXISTS src (key INT, value STRING)\")\n",
    "    # spark.sql(\"LOAD DATA LOCAL INPATH 'examples/src/main/resources/kv1.txt' INTO TABLE src\")\n",
    "    # spark.sql(\"CREATE TABLE IF NOT EXISTS tablea (key INT, value STRING)\")\n",
    "    # spark.sql(\"\"\"select * from finance_tepm into TABLE tablea\"\"\")\n",
    " # partitionBy 的分区字段的内容不能含有中文 (不识别中文)\n",
    "    financeBasicDF.write.mode('overwrite').saveAsTable('finance_hive',partitionBy='id')\n",
    "    financeBasicDF.show()\n",
    "    # hive_context.sql(\"\"\" select * from finance_hive\"\"\").show()\n",
    "\n",
    "def spark_hive():\n",
    "    # warehouse_location points to the default location for managed databases and tables\n",
    "    # warehouse_location = 'spark-warehouse'\n",
    "\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Py12122'1''thon Spark SQL Hive integration example\") \\\n",
    "        .config(\"spark.sql.warehouse.dir\", \"warehouse_location\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # path = \"/root/Documents/spark-test.csv\"\n",
    "    # path = \"/root/Documents/spark-test.csv\"\n",
    "    path = \"hdfs://172.172.172.166:8020/tmp/test/spark-test.csv\"\n",
    "\n",
    "    financeDF = spark.read.csv(path, header=True)\n",
    "    # financeDF.printSchema()\n",
    "\n",
    "    financeDF.createOrReplaceTempView(\"finance\")\n",
    "    financeBasicDF = spark.sql(\"\"\"select * from finance limit 10\"\"\")\n",
    "    financeBasicDF.show()\n",
    "    # financeBasicDF.cache()\n",
    "    financeBasicDF.registerTempTable('finance_tepm')\n",
    "\n",
    "    # spark is an existing SparkSession\n",
    "    # spark.sql(\"CREATE TABLE IF NOT EXISTS src (key INT, value STRING)\")\n",
    "    # spark.sql(\"LOAD DATA LOCAL INPATH 'examples/src/main/resources/kv1.txt' INTO TABLE src\")\n",
    "    # spark.sql(\"CREATE TABLE IF NOT EXISTS tablea (key INT, value STRING)\")\n",
    "    # spark.sql(\"\"\"select * from finance_tepm into TABLE tablea\"\"\")\n",
    "\n",
    "    # partitionBy 的分区字段的内容不能含有中文 (不识别中文)\n",
    "    financeBasicDF.write.mode('overwrite').saveAsTable('finance_hive1',partitionBy='date')\n",
    "    # financeBasicDF.write.mode('overwrite').saveAsTable('finance_hive1', partitionBy=['id','date'])\n",
    "    financeBasicDF.show()\n",
    "    # spark.sql(\"\"\" select * from finance_hive\"\"\").show()\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# def spark_init():\n",
    "#\n",
    "#\n",
    "#     spark = SparkSession \\\n",
    "#         .builder \\\n",
    "#         .appName(\"Python Spark SQL LEADER REPORT\") \\\n",
    "#         .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "#         .getOrCreate()\n",
    "#\n",
    "#     sc = spark.sparkContext\n",
    "#     # hiveContext=HiveContext(sc)\n",
    "#     # hiveContext.sql(\"use DataBaseName\")\n",
    "#\n",
    "#     # hdfs上文件存放路径\n",
    "#     # hdfs_file_path = \"hdfs://172.172.172.166:8020/user/qingchen.xue/hbase_data/\"\n",
    "#     path = \"/root/Documents/spark-test.csv\"\n",
    "#     print path\n",
    "#     #path = \"../spark-test.csv\"\n",
    "#\n",
    "#     financeDF = spark.read.csv(path, header=True)\n",
    "#     financeDF.printSchema()\n",
    "#\n",
    "#     financeDF.createOrReplaceTempView(\"finance\")\n",
    "#     # financeDF.createGlobalTempView(\"finance\")\n",
    "#\n",
    "#\n",
    "#     financeBasicDF = spark.sql(\"\"\" with aa as ( select date_format(add_months(regexp_replace(date,\"/\",\"-\"),-3),\"yyyy\")  as `财年`\n",
    "#         ,date_format(cast(regexp_replace(date,\"/\",\"-\") as date),\"yyyy-MM\") as `月份`\n",
    "#         ,date_format(add_months(regexp_replace(date,\"/\",\"-\"),-12),\"yyyy-MM\") as `去年同期月份`\n",
    "#         ,date `日期`,area `区域`,data_type `数据类型`,substring(data_type,5) `数据类型2`,\n",
    "#         sum( case when subject_type='收入' then money else 0 end ) as `全收入`,\n",
    "#         sum( case when subject_type='收入' and subject_code='60011108' then money else 0 end ) as `齿科双算`, -- 60011108收入\n",
    "#         sum( case when subject_detail_type='体检收入' then money else 0 end ) as `体检收入`,\n",
    "#         sum( case when subject_code='64010201' or subject_code='64010202' then money else 0 end ) as  `变动成本1` ,   --64010201 and 64010202\n",
    "#         sum( case when subject_detail_type='疾病检测收入' then money else 0 end ) as `疾病检测收入`,\n",
    "#         sum( case when subject_detail_type='齿科收入' then money else 0 end ) as `齿科收入`,\n",
    "#         sum( case when subject_code='64010221' then money else 0 end ) as `变动成本3`   ,  --64010221L\n",
    "#         sum( case when subject_detail_type='门诊收入' then money else 0 end ) as `门诊收入`,\n",
    "#         sum( case when subject_code='64010222' then money else 0 end ) as `变动成本4`  , --64010222\n",
    "#         sum( case when subject_detail_type='医疗管理收入' then money else 0 end ) as `医疗管理收入`,\n",
    "#         sum( case when subject_code='64010211' then money else 0 end ) as `变动成本5`,   --64010211\n",
    "#         sum( case when subject_detail_type='销售商品收入' then money else 0 end ) as `销售商品收入`,\n",
    "#         sum( case when subject_detail_type='其他收入' then money else 0 end ) as `其他收入`,\n",
    "#         sum( case when subject_detail_type='落关联成本' then money else 0 end ) as `落关联成本`,\n",
    "#         sum( case when subject_type='成本费用' then money else 0 end ) as `成本费用`,\n",
    "#         nvl( sum( case when subject_type='收入' then money else 0 end ),0)-nvl(sum( case when subject_type='收入' and subject_code='60011108' then money else 0 end ),0) as `收入`,\n",
    "#         nvl( sum( case when subject_type='收入' then money else 0 end ),0)-nvl(sum( case when subject_type='成本费用' then money else 0 end ) ,0) as `税前利润`,\n",
    "#         case when area in ('西康','华检','元化医疗','健维管理','臻景','香港','BVI') then '非一体化'  else '一体化' end as `是否一体化`\n",
    "#         from finance\n",
    "#         group by date_format(add_months(regexp_replace(date,\"/\",\"-\"),-3),\"yyyy\")\n",
    "#             ,date_format(cast(regexp_replace(date,\"/\",\"-\") as date),\"yyyy-MM\")\n",
    "#             ,date_format(add_months(regexp_replace(date,\"/\",\"-\"),-12),\"yyyy-MM\")\n",
    "#             ,date ,area ,data_type,substring(data_type,5)\n",
    "#             ,case when area in ('西康','华检','元化医疗','健维管理','臻景','香港','BVI') then '非一体化' else '一体化' end\n",
    "#         )\n",
    "#         ,a1 as ( --今年和去年同期 处理为一条\n",
    "#         select\n",
    "#         a1.`财年`,a1.`月份`,a1.`区域`,a1.`数据类型`,a1.`数据类型2`,a1.`是否一体化`,\n",
    "#         a1.`体检收入`,a1.`变动成本1`,a1.`疾病检测收入`,a1.`齿科收入`,a1.`变动成本3`,a1.`门诊收入`,a1.`变动成本4`,a1.`医疗管理收入`,\n",
    "#         a1.`变动成本5`,a1.`销售商品收入`,a1.`其他收入`,a1.`落关联成本`,a1.`收入`,\n",
    "#         a0.`体检收入` as `去年同期体检收入`,  a0.`变动成本1` as `去年同期变动成本1`, a0.`疾病检测收入` as `去年同期疾病检测收入`,\n",
    "#         a0.`齿科收入` as `去年同期齿科收入`,  a0.`变动成本3` as `去年同期变动成本3`, a0.`门诊收入` as `去年同期门诊收入`,\n",
    "#         a0.`变动成本4`  as `去年同期变动成本4`,   a0.`医疗管理收入`  as `去年同期医疗管理收入`,a0.`变动成本5` as `去年同期变动成本5`,\n",
    "#         a1.`销售商品收入`as `去年同期销售商品收入`,a1.`其他收入` as `去年同期其他收入`,    a1.`落关联成本` as `去年同期落关联成本`,\n",
    "#         a1.`收入` as `去年同期收入`\n",
    "#         from aa a1\n",
    "#         left join aa a0 on a1.`区域`=a0.`区域` and a1.`数据类型2`=a0.`数据类型2` and a1.`去年同期月份`=a0.`月份`\n",
    "#         )\n",
    "#         select * from a1 limit 2\n",
    "#         --后续添加各种逻辑sql\n",
    "#         \"\"\")\n",
    "#\n",
    "#     financeBasicDF.show()\n",
    "# #     # financeBasicDF.createGlobalTempView(\"financeBasic\")\n",
    "#     financeBasicDF.saveAsTable('financeBasic')\n",
    "#\n",
    "# # partitionBy 的分区字段的内容不能含有中文 (不识别中文)\n",
    "#\n",
    "\n",
    "# def read_spark():\n",
    "#     sc=spark.sparkContext\n",
    "#     path=\"../../spark-test.csv\"\n",
    "#     print path\n",
    "\n",
    "# financeDF=spark.read.csv(path)\n",
    "#peopleDF.printSchema()\n",
    "\n",
    "# financeDF.createGlobalTempView(\"finance\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    spark_hive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
